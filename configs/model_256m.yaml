# SmolVLM2-256M Model Configuration
# Total params: ~256M (93M vision + 135M text + ~28M connector)

model:
  name: smolvlm2-256m
  size: 256m

  # Vision encoder (SigLIP)
  vision_encoder:
    name: google/siglip-base-patch16-512
    hidden_size: 768
    image_size: 384
    patch_size: 16
    freeze_initially: true
    unfreeze_after_steps: 10000

  # Text decoder (SmolLM2-135M)
  text_decoder:
    name: HuggingFaceTB/SmolLM2-135M-Instruct
    hidden_size: 576
    vocab_size: 49152
    max_position_embeddings: 16384
    rope_theta: 273000

  # Pixel shuffle connector
  connector:
    type: pixel_shuffle
    ratio: 3  # 9x compression
    hidden_size: 576
    num_layers: 2

  # Visual tokens
  visual_tokens:
    tokens_per_patch: 81  # (24/3)^2 per 384x384 patch
    max_image_patches: 36
    image_token: "<image>"
    video_token: "<video>"

# Precision
precision:
  dtype: bfloat16
  gradient_checkpointing: true

# Special tokens
special_tokens:
  - "<image>"
  - "<video>"
  - "<image_start>"
  - "<image_end>"
